{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_ich_detection_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wugzdoai7tq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout, InputLayer, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "import keras\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilmoElHluNpF",
        "colab_type": "code",
        "outputId": "30c662b6-14dd-42bc-f364-036fbbdf85c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5I2-eSvztwN",
        "colab_type": "text"
      },
      "source": [
        "Useful variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxx-mRDqzwUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASS = 5\n",
        "TRAIN_SIZE = 1440\n",
        "VAL_SIZE = 160\n",
        "TEST_SIZE = 400\n",
        "BATCH = 32\n",
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224\n",
        "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnFwV-rjslve",
        "colab_type": "text"
      },
      "source": [
        "Get all the train files for each hemorrhage from their directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsnOPRDDkCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# intraparenchymal\n",
        "ip_files = glob.glob('/content/drive/My Drive/data/intraparenchymal/*')\n",
        "ip_train_files = [fn for fn in ip_files if 'ID' in fn] \n",
        "\n",
        "# none\n",
        "none_files = glob.glob('/content/drive/My Drive/data/none/*')\n",
        "none_train_files = [fn for fn in none_files if 'ID' in fn] \n",
        "\n",
        "# epidural\n",
        "ep_files = glob.glob('/content/drive/My Drive/data/epidural/*')\n",
        "ep_train_files = [fn for fn in ep_files if 'ID' in fn]\n",
        "\n",
        "# intraventricular\n",
        "iv_files = glob.glob('/content/drive/My Drive/data/intraventricular/*')\n",
        "iv_train_files = [fn for fn in iv_files if 'ID' in fn]\n",
        "\n",
        "# subarachnoid\n",
        "sa_files = glob.glob('/content/drive/My Drive/data/subarachnoid/*')\n",
        "sa_train_files = [fn for fn in sa_files if 'ID' in fn]\n",
        "\n",
        "# subdural\n",
        "sd_files = glob.glob('/content/drive/My Drive/data/subdural/*')\n",
        "sd_train_files = [fn for fn in sd_files if 'ID' in fn]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eYQMav9tSzc",
        "colab_type": "text"
      },
      "source": [
        "Get all the test files for each hemorrhage from their directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saPiN3Fg9Cvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# intraparenchymal\n",
        "ip_test_files = glob.glob('/content/drive/My Drive/data/intraparenchymal/test/*')\n",
        "ip_test_files = [fn for fn in ip_test_files] \n",
        "\n",
        "# none\n",
        "none_test_files = glob.glob('/content/drive/My Drive/data/none/test/*')\n",
        "non_test_files = [fn for fn in none_test_files] \n",
        "\n",
        "# epidural\n",
        "ep_test_files = glob.glob('/content/drive/My Drive/data/epidural/test/*')\n",
        "ep_test_files = [fn for fn in ep_test_files] \n",
        "\n",
        "# intraventricular\n",
        "iv_test_files = glob.glob('/content/drive/My Drive/data/intraventricular/test/*')\n",
        "iv_test_files = [fn for fn in iv_test_files if 'ID' in fn]\n",
        "\n",
        "# subarachnoid\n",
        "sa_test_files = glob.glob('/content/drive/My Drive/data/subarachnoid/test/*')\n",
        "sa_test_files = [fn for fn in sa_test_files if 'ID' in fn]\n",
        "\n",
        "# subdural\n",
        "sd_test_files = glob.glob('/content/drive/My Drive/data/subdural/test/*')\n",
        "sd_test_files = [fn for fn in sd_test_files if 'ID' in fn]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ercr77ouWXu",
        "colab_type": "text"
      },
      "source": [
        "Organize data into train, validation, and test sets for each hemorrhage type and then concatenate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ettJW-5Dnyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# intraparenchymal\n",
        "ip_train = np.random.choice(ip_train_files, size=TRAIN_SIZE, replace=False)\n",
        "ip_files = list(set(ip_train_files) - set(ip_train))\n",
        "ip_val = np.random.choice(ip_files, size=VAL_SIZE, replace=False) \n",
        "ip_test = np.random.choice(ip_test_files, size=TEST_SIZE, replace = False)\n",
        "\n",
        "# none\n",
        "none_train = np.random.choice(none_train_files, size=TRAIN_SIZE, replace=False)\n",
        "none_files = list(set(none_train_files) - set(none_train))\n",
        "none_val = np.random.choice(none_files, size=VAL_SIZE, replace=False)\n",
        "none_test = np.random.choice(none_test_files, size=TEST_SIZE, replace = False)\n",
        "\n",
        "# epidural\n",
        "ep_train = np.random.choice(ep_train_files, size=TRAIN_SIZE, replace=False) \n",
        "ep_files = list(set(ep_train_files) - set(ep_train))\n",
        "ep_val = np.random.choice(ep_files, size=VAL_SIZE, replace=False) \n",
        "ep_test = np.random.choice(ep_test_files, size=TEST_SIZE, replace = False)\n",
        "\n",
        "# intraventricular\n",
        "iv_train = np.random.choice(iv_train_files, size=TRAIN_SIZE, replace=False) \n",
        "iv_files = list(set(iv_train_files) - set(iv_train))\n",
        "iv_val = np.random.choice(iv_files, size=VAL_SIZE, replace=False) \n",
        "iv_test = np.random.choice(iv_test_files, size=TEST_SIZE, replace = False)\n",
        "\n",
        "# subarachnoid\n",
        "sa_train = np.random.choice(sa_train_files, size=TRAIN_SIZE, replace=False) \n",
        "sa_files = list(set(sa_train_files) - set(sa_train))\n",
        "sa_val = np.random.choice(sa_files, size=VAL_SIZE, replace=False) \n",
        "sa_test = np.random.choice(sa_test_files, size=TEST_SIZE, replace = False)\n",
        "\n",
        "# subdural\n",
        "sd_train = np.random.choice(sd_train_files, size=TRAIN_SIZE, replace=False) \n",
        "sd_files = list(set(sd_train_files) - set(sd_train))\n",
        "sd_val = np.random.choice(sd_files, size=VAL_SIZE, replace=False) \n",
        "sd_test = np.random.choice(sd_test_files, size=TEST_SIZE, replace = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmNth2PmvsSV",
        "colab_type": "text"
      },
      "source": [
        "Load images as arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skXs6DYjDqWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# intraparenchymal\n",
        "ip_files = glob.glob('/content/drive/My Drive/data/intraparenchymal/*')\n",
        "ip_train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in ip_files if img in ip_train]\n",
        "ip_train_imgs = np.array(ip_train_imgs)\n",
        "ip_train_labels = ['intraparenchymal' for img in ip_files if img in ip_train]\n",
        "\n",
        "ip_val_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in ip_files if img in ip_val]\n",
        "ip_val_imgs = np.array(ip_val_imgs)\n",
        "ip_val_labels = ['intraparenchymal' for img in ip_files if img in ip_val]\n",
        "\n",
        "ip_test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in ip_test]\n",
        "ip_test_imgs = np.array(ip_test_imgs)\n",
        "ip_test_labels = ['intraparenchymal' for img in ip_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVy9izrgiH9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# none\n",
        "none_files = glob.glob('/content/drive/My Drive/data/none/*')\n",
        "none_train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in none_files if img in none_train]\n",
        "none_train_imgs = np.array(none_train_imgs)\n",
        "none_train_labels = ['none' for img in none_files if img in none_train]\n",
        "\n",
        "none_val_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in none_files if img in none_val]\n",
        "none_train_imgs = np.array(none_train_imgs)\n",
        "none_val_labels = ['none' for img in none_files if img in none_val]\n",
        "\n",
        "none_test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in none_test]\n",
        "none_test_imgs = np.array(none_test_imgs)\n",
        "none_test_labels = ['none' for img in none_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9fHWyZDiIdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epidural\n",
        "ep_files = glob.glob('/content/drive/My Drive/data/epidural/*')\n",
        "ep_train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in ep_files if img in ep_train]\n",
        "ep_train_imgs = np.array(ep_train_imgs)\n",
        "ep_train_labels = ['epidural' for img in ep_files if img in ep_train]\n",
        "\n",
        "ep_val_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in ep_files if img in ep_val]\n",
        "ep_val_imgs = np.array(ep_val_imgs)\n",
        "ep_val_labels = ['epidural' for img in ep_files if img in ep_val]\n",
        "\n",
        "ep_test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in ep_test]\n",
        "ep_test_imgs = np.array(ep_test_imgs)\n",
        "ep_test_labels = ['epidural' for img in ep_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvHTHGahiIpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# intraventricular\n",
        "iv_files = glob.glob('/content/drive/My Drive/data/intraventricular/*')\n",
        "iv_train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in iv_files if img in iv_train]\n",
        "iv_train_imgs = np.array(iv_train_imgs)\n",
        "iv_train_labels = ['intraventricular' for img in iv_files if img in iv_train]\n",
        "\n",
        "iv_val_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in iv_files if img in iv_val]\n",
        "iv_val_imgs = np.array(iv_val_imgs)\n",
        "iv_val_labels = ['intraventricular' for img in iv_files if img in iv_val]\n",
        "\n",
        "iv_test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in iv_test]\n",
        "iv_test_imgs = np.array(iv_test_imgs)\n",
        "iv_test_labels = ['intraventricular' for img in iv_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQFWyheHiI2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subarachnoid\n",
        "sa_files = glob.glob('/content/drive/My Drive/data/subarachnoid/*')\n",
        "sa_train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in sa_files if img in sa_train]\n",
        "sa_train_imgs = np.array(sa_train_imgs)\n",
        "sa_train_labels = ['subarachnoid' for img in sa_files if img in sa_train]\n",
        "\n",
        "sa_val_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in sa_files if img in sa_val]\n",
        "sa_val_imgs = np.array(sa_val_imgs)\n",
        "sa_val_labels = ['subarachnoid' for img in sa_files if img in sa_val]\n",
        "\n",
        "sa_test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in sa_test]\n",
        "sa_test_imgs = np.array(sa_test_imgs)\n",
        "sa_test_labels = ['subarachnoid' for img in sa_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I_HbxEMiJDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subdural\n",
        "sd_files = glob.glob('/content/drive/My Drive/data/subdural/*')\n",
        "sd_train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in sd_files if img in sd_train]\n",
        "sd_train_imgs = np.array(sd_train_imgs)\n",
        "sd_train_labels = ['subdural' for img in sd_files if img in sd_train]\n",
        "\n",
        "sd_val_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in sd_files if img in sd_val]\n",
        "sd_val_imgs = np.array(sd_val_imgs)\n",
        "sd_val_labels = ['subdural' for img in sd_files if img in sd_val]\n",
        "\n",
        "sd_test_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in sd_test]\n",
        "sd_test_imgs = np.array(sd_test_imgs)\n",
        "sd_test_labels = ['subdural' for img in sd_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-ZwVV4-wIwq",
        "colab_type": "text"
      },
      "source": [
        "Concatenate train, validation, and test data to create complete sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jLN2gBiENEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hem_train = []\n",
        "hem_val = []\n",
        "hem_test = []\n",
        "\n",
        "for j in range(0,6):\n",
        "  for i in range(0, TRAIN_SIZE):\n",
        "    if(j == 5):\n",
        "      hem_train.append('no')\n",
        "    else:\n",
        "      hem_train.append('yes')\n",
        "\n",
        "for j in range(0,6):\n",
        "  for i in range(0, VAL_SIZE):\n",
        "    if(j == 5):\n",
        "      hem_val.append('no')\n",
        "    else:\n",
        "      hem_val.append('yes')\n",
        "\n",
        "for j in range(0,6):\n",
        "  for i in range(0, TEST_SIZE):\n",
        "    if(j == 5):\n",
        "      hem_test.append('no')\n",
        "    else:\n",
        "      hem_test.append('yes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i124B12V7EDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imgs = np.concatenate([ip_train_imgs, \n",
        "                             ep_train_imgs,\n",
        "                             iv_train_imgs,\n",
        "                             sa_train_imgs,\n",
        "                             sd_train_imgs,\n",
        "                             none_train_imgs])\n",
        "train_labels = hem_train\n",
        "\n",
        "val_imgs = np.concatenate([ip_val_imgs, \n",
        "                           ep_val_imgs,\n",
        "                           iv_val_imgs,\n",
        "                           sa_val_imgs,\n",
        "                           sd_val_imgs,\n",
        "                           none_val_imgs])\n",
        "val_labels = hem_val\n",
        "\n",
        "test_imgs = np.concatenate([ip_test_imgs, \n",
        "                            ep_test_imgs,\n",
        "                            iv_test_imgs,\n",
        "                            sa_test_imgs,\n",
        "                            sd_test_imgs,\n",
        "                            none_test_imgs])\n",
        "test_labels = hem_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LN2a_bFxPQk",
        "colab_type": "text"
      },
      "source": [
        "Encode text category labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hndl8320DwDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder() \n",
        "le.fit(train_labels) \n",
        "\n",
        "# encoding\n",
        "train_labels_enc = le.transform(train_labels) \n",
        "val_labels_enc = le.transform(val_labels) \n",
        "test_labels_enc = le.transform(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8fCaul1xks5",
        "colab_type": "text"
      },
      "source": [
        "Create image data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wve-zN3kDy56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    zoom_range=[0,1], \n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.05, \n",
        "    height_shift_range=0.05, \n",
        "    shear_range=0.05, \n",
        "    horizontal_flip=True, \n",
        "    fill_mode='nearest')\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(train_imgs, train_labels_enc,batch_size=BATCH)\n",
        "val_generator = val_datagen.flow(val_imgs, val_labels_enc, batch_size=BATCH)\n",
        "test_generator = test_datagen.flow(test_imgs, test_labels_enc, batch_size=BATCH, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02xW0PkTyf1_",
        "colab_type": "text"
      },
      "source": [
        "Create model using transfer learning with ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdyc5TRRvcMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "\n",
        "# making only batch normalization layers trainable\n",
        "for layer in resnet_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "bin_model = Sequential()\n",
        "bin_model.add(resnet_model)\n",
        "bin_model.add(GlobalAveragePooling2D())\n",
        "bin_model.add(Dense(256, activation='relu'))\n",
        "bin_model.add(Dropout(.4))\n",
        "bin_model.add(BatchNormalization())\n",
        "\n",
        "# binary classification\n",
        "bin_model.add(Dense(1, activation='sigmoid'))\n",
        "bin_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNFAkLyXEJGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TOTAL_TRAIN = TRAIN_SIZE * (NUM_CLASS+1)\n",
        "TOTAL_VAL = VAL_SIZE * (NUM_CLASS+1)\n",
        "\n",
        "history = bin_model.fit_generator(train_generator, \n",
        "                              steps_per_epoch=TOTAL_TRAIN//BATCH, \n",
        "                              epochs=15,\n",
        "                              validation_data=val_generator, \n",
        "                              validation_steps=TOTAL_VAL//BATCH, \n",
        "                              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QdHI7JBFZVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bin_model.save('binary_class_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYvioksXF6qp",
        "colab": {}
      },
      "source": [
        "bin_model.evaluate(test_generator, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bglKzUjFLghs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confusion matrix\n",
        "y_pred = bin_model.predict(test_generator)\n",
        "for i in y_pred:\n",
        "  i[0] = round(i[0])\n",
        "\n",
        "print('Confusion Matrix')\n",
        "print(pd.DataFrame(confusion_matrix(test_labels_enc, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KNzYKtMFGAOt",
        "colab": {}
      },
      "source": [
        "bin_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rHYcTPZQGCpq",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NM4hk2aLGGV0",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gMIwpCxuB7tC"
      },
      "source": [
        "Concatenate train, validation, and test data to create complete sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "85QqdstlGI1J",
        "colab": {}
      },
      "source": [
        "train_imgs = np.concatenate([ip_train_imgs, \n",
        "                             ep_train_imgs,\n",
        "                             iv_train_imgs,\n",
        "                             sa_train_imgs,\n",
        "                             sd_train_imgs])\n",
        "train_labels = ip_train_labels + ep_train_labels + iv_train_labels + sa_train_labels + sd_train_labels\n",
        "\n",
        "val_imgs = np.concatenate([ip_val_imgs, \n",
        "                           ep_val_imgs,\n",
        "                           iv_val_imgs,\n",
        "                           sa_val_imgs,\n",
        "                           sd_val_imgs])\n",
        "val_labels = ip_val_labels + ep_val_labels + iv_val_labels + sa_val_labels + sd_val_labels\n",
        "\n",
        "test_imgs = np.concatenate([ip_test_imgs,  \n",
        "                            ep_test_imgs,\n",
        "                            iv_test_imgs,\n",
        "                            sa_test_imgs,\n",
        "                            sd_test_imgs])\n",
        "test_labels = ip_test_labels + ep_test_labels + iv_test_labels + sa_test_labels + sd_test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s7aXAh1WCMiD"
      },
      "source": [
        "Encode text category labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q6Xe4wCvGLPP",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder() \n",
        "le.fit(train_labels) \n",
        "\n",
        "# encoding\n",
        "train_labels_enc = le.transform(train_labels) \n",
        "val_labels_enc = le.transform(val_labels) \n",
        "test_labels_enc = le.transform(test_labels)\n",
        "test_labels_cm = test_labels_enc\n",
        "\n",
        "# one hot encoding\n",
        "train_labels_enc = to_categorical(train_labels_enc) \n",
        "val_labels_enc = to_categorical(val_labels_enc) \n",
        "test_labels_enc = to_categorical(test_labels_enc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tKnjhkdJCVjl"
      },
      "source": [
        "Create image data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhs7jjl5GN5p",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    zoom_range=[0,1], \n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.05, \n",
        "    height_shift_range=0.05, \n",
        "    shear_range=0.05, \n",
        "    horizontal_flip=True, \n",
        "    fill_mode='nearest')\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(train_imgs, train_labels_enc,batch_size=BATCH)\n",
        "val_generator = val_datagen.flow(val_imgs, val_labels_enc, batch_size=BATCH)\n",
        "test_generator = test_datagen.flow(test_imgs, test_labels_enc, batch_size=BATCH, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D6NxGF5KCdXC"
      },
      "source": [
        "Create model using transfer learning with ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x-sGGnbOGQ89",
        "colab": {}
      },
      "source": [
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "\n",
        "# making only batch normalization layers trainable\n",
        "for layer in resnet_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "multi_model = Sequential()\n",
        "multi_model.add(resnet_model)\n",
        "multi_model.add(GlobalAveragePooling2D())\n",
        "multi_model.add(Dense(256, activation='relu'))\n",
        "multi_model.add(Dropout(.3))\n",
        "multi_model.add(BatchNormalization())\n",
        "\n",
        "# multi-class classification\n",
        "multi_model.add(Dense(NUM_CLASS, activation='softmax'))\n",
        "multi_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5QJM3Oj0GUOA",
        "colab": {}
      },
      "source": [
        "TOTAL_TRAIN = TRAIN_SIZE * NUM_CLASS\n",
        "TOTAL_VAL = VAL_SIZE * NUM_CLASS\n",
        "\n",
        "history = multi_model.fit_generator(train_generator, \n",
        "                              steps_per_epoch=TOTAL_TRAIN//BATCH, \n",
        "                              epochs=90,\n",
        "                              validation_data=val_generator, \n",
        "                              validation_steps=TOTAL_VAL//BATCH, \n",
        "                              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GK9T41GGmpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_model.save('multi_class_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UbEwN6DcGWXM",
        "colab": {}
      },
      "source": [
        "multi_model.evaluate(test_generator, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anWWgI0mLlmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confusion matrix\n",
        "y_pred = multi_model.predict(test_generator, verbose=2)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print('Confusion Matrix')\n",
        "print(pd.DataFrame(confusion_matrix(test_labels_cm, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1gAD7c8Yu4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_048UMrHCzAb",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_UzWjyprC1pS",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}